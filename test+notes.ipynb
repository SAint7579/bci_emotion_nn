{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "* 32 participants [s01 to s32]\n",
    "* 40 pieces of music\n",
    "* 40 channels out of which the first 32 are relevant \n",
    "* 8064 readings recorded at 128Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deap_pre_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Reading subject: s01 Media: 1\n"
     ]
    }
   ],
   "source": [
    "eeg1d,eeg2d,val,aro = get_subject_data(subject_no=1,media_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7680"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eeg2d.reshape(-1,9,9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 9, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val,aro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dummy network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn_function import *\n",
    "from cnn_function import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constant :\n",
    "WINDOW_SIZE = 64\n",
    "#For rnn layers\n",
    "INPUT_NODES = 32\n",
    "HIDDEN_ST = 32\n",
    "HOLD_PROBA = 0.5\n",
    "RNN_INPUT_SIZE = 32\n",
    "\n",
    "#For cnn layers\n",
    "CONV_IP_SHAPE = [-1,9,9,1]\n",
    "CONV1_KERNEL = [4,4,1,32]\n",
    "CONV2_KERNEL = [4,4,32,64]\n",
    "CONV3_KERNEL = [4,4,64,128]\n",
    "REDUCTION_KERNEL = [1,1,128*WINDOW_SIZE,13]\n",
    "\n",
    "#For dnn layers (for the paper code)\n",
    "N_FC_IN = 1024\n",
    "N_FC_OUT= 1024\n",
    "\n",
    "#FOR PREDICTIONS\n",
    "N_LABELS = 2\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION FORM https://github.com/ynulonger/ijcnn/blob/master/cv.py\n",
    "#FOR SHAPING THE INPUT OF LSTM\n",
    "def apply_fully_connect(x, x_size, fc_size):\n",
    "    fc_weight = init_weight([x_size, fc_size])\n",
    "    fc_bias = init_bias([fc_size])\n",
    "    return tf.nn.elu(tf.add(tf.matmul(x, fc_weight), fc_bias))\n",
    "\n",
    "#FOR READOUT OF THE FINAL LAYER\n",
    "def apply_readout(x, x_size, readout_size):\n",
    "    readout_weight = init_weight([x_size, readout_size])\n",
    "    readout_bias = init_bias([readout_size])\n",
    "    return tf.add(tf.matmul(x, readout_weight), readout_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting tf default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#CNN placeholders and model variables\n",
    "x_data_cnn = tf.placeholder(dtype = tf.float32,shape=(None,9,9),name='cnn_data')\n",
    "x_image = tf.reshape(x_data_cnn,CONV_IP_SHAPE,name='cnn_image')\n",
    "\n",
    "#LAYERS\n",
    "conv1 = conv_layer(x_image,CONV1_KERNEL,name=\"convo_l1\")\n",
    "conv2 = conv_layer(conv1,CONV2_KERNEL,name=\"convo_l2\")\n",
    "conv3 = conv_layer(conv2,CONV3_KERNEL,name=\"convo_l3\")\n",
    "\n",
    "#Depth variable\n",
    "depth = tf.reshape(conv3,[-1,9,9,128* WINDOW_SIZE])\n",
    "\n",
    "#Size reduction conv layer\n",
    "reduced_data = conv_layer(depth,REDUCTION_KERNEL,name=\"conv_reduced\")\n",
    "\n",
    "#Flattening convolution layer\n",
    "shape = reduced_data.get_shape().as_list()\n",
    "final_flat = tf.reshape(reduced_data, [-1, shape[1] * shape[2] * shape[3]])\n",
    "cnn_out_fuse = final_flat\n",
    "\n",
    "#RNN placeholder and model variables\n",
    "x_data_rnn = tf.placeholder(dtype = tf.float32,shape=(None,WINDOW_SIZE,INPUT_NODES),name='rnn_data') #TIME_STEP = WINDOW_SIZE\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Shaping the RNN input\n",
    "shape = x_data_rnn.get_shape().as_list()\n",
    "rnn_in_flat = tf.reshape(x_data_rnn, [-1, shape[2]]) #[batch_size*n_time_step, n_electrode]\n",
    "rnn_fc_in = apply_fully_connect(rnn_in_flat, shape[2], N_FC_IN) #[batch_size*n_time_step, n_electrode]\n",
    "lstm_in = tf.reshape(rnn_fc_in, [-1,WINDOW_SIZE,N_FC_IN]) #[batch_size, n_time_step, n_fc_in]\n",
    "\n",
    "#Making cells\n",
    "cell1 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cell2 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cells = [cell1,cell2]\n",
    "final_cell = create_Stacked_cell(cells)\n",
    "\n",
    "#Laying out the network\n",
    "output, states = create_RNN(final_cell,lstm_in)\n",
    "\n",
    "#Unstacking the output\n",
    "output = tf.unstack(tf.transpose(output, [1, 0, 2]), name='lstm_out')\n",
    "\n",
    "#Selecting the final output form the layer\n",
    "rnn_output = output[-1] #[batch, fc_size]\n",
    "\n",
    "#Shaping the output\n",
    "lstm_fc_out = dnn_layer(rnn_output,N_FC_OUT) #[batch_size, n_fc_out]\n",
    "lstm_fc_drop = tf.nn.dropout(lstm_fc_out, keep_prob)\n",
    "\n",
    "#Placeholder for true values\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=(None,N_LABELS)) #[Valance, Arousal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fuse_cnn_rnn: [None, 2077]\n"
     ]
    }
   ],
   "source": [
    "#Flattening the layer\n",
    "final_connected_layer = tf.concat([cnn_out_fuse, lstm_fc_drop], axis=1)\n",
    "shape = final_connected_layer.get_shape().as_list()\n",
    "print(\"\\nfuse_cnn_rnn:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating output variables \n",
    "y_ = apply_readout(final_connected_layer, shape[1], N_LABELS)\n",
    "y_pred = tf.argmax(tf.nn.softmax(y_), 1, name=\"y_pred\")\n",
    "y_posi = tf.nn.softmax(y_, name=\"y_posi\")\n",
    "\n",
    "#Making cost functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y_true), name='loss')\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saver and variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMAINING:\n",
    "* Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 9, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Reading subject: s01 Media: 1\n",
      "WINDOW FROM 0  TO  64\n",
      "WINDOW FROM 64  TO  128\n",
      "WINDOW FROM 128  TO  192\n",
      "WINDOW FROM 192  TO  256\n",
      "WINDOW FROM 256  TO  320\n",
      "WINDOW FROM 320  TO  384\n",
      "WINDOW FROM 384  TO  448\n",
      "WINDOW FROM 448  TO  512\n",
      "WINDOW FROM 512  TO  576\n",
      "WINDOW FROM 576  TO  640\n",
      "WINDOW FROM 640  TO  704\n",
      "WINDOW FROM 704  TO  768\n",
      "WINDOW FROM 768  TO  832\n",
      "WINDOW FROM 832  TO  896\n",
      "WINDOW FROM 896  TO  960\n",
      "WINDOW FROM 960  TO  1024\n",
      "WINDOW FROM 1024  TO  1088\n",
      "WINDOW FROM 1088  TO  1152\n",
      "WINDOW FROM 1152  TO  1216\n",
      "WINDOW FROM 1216  TO  1280\n",
      "WINDOW FROM 1280  TO  1344\n",
      "WINDOW FROM 1344  TO  1408\n",
      "WINDOW FROM 1408  TO  1472\n",
      "WINDOW FROM 1472  TO  1536\n",
      "WINDOW FROM 1536  TO  1600\n",
      "WINDOW FROM 1600  TO  1664\n",
      "WINDOW FROM 1664  TO  1728\n",
      "WINDOW FROM 1728  TO  1792\n",
      "WINDOW FROM 1792  TO  1856\n",
      "WINDOW FROM 1856  TO  1920\n",
      "WINDOW FROM 1920  TO  1984\n",
      "WINDOW FROM 1984  TO  2048\n",
      "WINDOW FROM 2048  TO  2112\n",
      "WINDOW FROM 2112  TO  2176\n",
      "WINDOW FROM 2176  TO  2240\n",
      "WINDOW FROM 2240  TO  2304\n",
      "WINDOW FROM 2304  TO  2368\n",
      "WINDOW FROM 2368  TO  2432\n",
      "WINDOW FROM 2432  TO  2496\n",
      "WINDOW FROM 2496  TO  2560\n",
      "WINDOW FROM 2560  TO  2624\n",
      "WINDOW FROM 2624  TO  2688\n",
      "WINDOW FROM 2688  TO  2752\n",
      "WINDOW FROM 2752  TO  2816\n",
      "WINDOW FROM 2816  TO  2880\n",
      "WINDOW FROM 2880  TO  2944\n",
      "WINDOW FROM 2944  TO  3008\n",
      "WINDOW FROM 3008  TO  3072\n",
      "WINDOW FROM 3072  TO  3136\n",
      "WINDOW FROM 3136  TO  3200\n",
      "WINDOW FROM 3200  TO  3264\n",
      "WINDOW FROM 3264  TO  3328\n",
      "WINDOW FROM 3328  TO  3392\n",
      "WINDOW FROM 3392  TO  3456\n",
      "WINDOW FROM 3456  TO  3520\n",
      "WINDOW FROM 3520  TO  3584\n",
      "WINDOW FROM 3584  TO  3648\n",
      "WINDOW FROM 3648  TO  3712\n",
      "WINDOW FROM 3712  TO  3776\n",
      "WINDOW FROM 3776  TO  3840\n",
      "WINDOW FROM 3840  TO  3904\n",
      "WINDOW FROM 3904  TO  3968\n",
      "WINDOW FROM 3968  TO  4032\n",
      "WINDOW FROM 4032  TO  4096\n",
      "WINDOW FROM 4096  TO  4160\n",
      "WINDOW FROM 4160  TO  4224\n",
      "WINDOW FROM 4224  TO  4288\n",
      "WINDOW FROM 4288  TO  4352\n",
      "WINDOW FROM 4352  TO  4416\n",
      "WINDOW FROM 4416  TO  4480\n",
      "WINDOW FROM 4480  TO  4544\n",
      "WINDOW FROM 4544  TO  4608\n",
      "WINDOW FROM 4608  TO  4672\n",
      "WINDOW FROM 4672  TO  4736\n",
      "WINDOW FROM 4736  TO  4800\n",
      "WINDOW FROM 4800  TO  4864\n",
      "WINDOW FROM 4864  TO  4928\n",
      "WINDOW FROM 4928  TO  4992\n",
      "WINDOW FROM 4992  TO  5056\n",
      "WINDOW FROM 5056  TO  5120\n",
      "WINDOW FROM 5120  TO  5184\n",
      "WINDOW FROM 5184  TO  5248\n",
      "WINDOW FROM 5248  TO  5312\n",
      "WINDOW FROM 5312  TO  5376\n",
      "WINDOW FROM 5376  TO  5440\n",
      "WINDOW FROM 5440  TO  5504\n",
      "WINDOW FROM 5504  TO  5568\n",
      "WINDOW FROM 5568  TO  5632\n",
      "WINDOW FROM 5632  TO  5696\n",
      "WINDOW FROM 5696  TO  5760\n",
      "WINDOW FROM 5760  TO  5824\n",
      "WINDOW FROM 5824  TO  5888\n",
      "WINDOW FROM 5888  TO  5952\n",
      "WINDOW FROM 5952  TO  6016\n",
      "WINDOW FROM 6016  TO  6080\n",
      "WINDOW FROM 6080  TO  6144\n",
      "WINDOW FROM 6144  TO  6208\n",
      "WINDOW FROM 6208  TO  6272\n",
      "WINDOW FROM 6272  TO  6336\n",
      "WINDOW FROM 6336  TO  6400\n",
      "WINDOW FROM 6400  TO  6464\n",
      "WINDOW FROM 6464  TO  6528\n",
      "WINDOW FROM 6528  TO  6592\n",
      "WINDOW FROM 6592  TO  6656\n",
      "WINDOW FROM 6656  TO  6720\n",
      "WINDOW FROM 6720  TO  6784\n",
      "WINDOW FROM 6784  TO  6848\n",
      "WINDOW FROM 6848  TO  6912\n",
      "WINDOW FROM 6912  TO  6976\n",
      "WINDOW FROM 6976  TO  7040\n",
      "WINDOW FROM 7040  TO  7104\n",
      "WINDOW FROM 7104  TO  7168\n",
      "WINDOW FROM 7168  TO  7232\n",
      "WINDOW FROM 7232  TO  7296\n",
      "WINDOW FROM 7296  TO  7360\n",
      "WINDOW FROM 7360  TO  7424\n",
      "WINDOW FROM 7424  TO  7488\n",
      "WINDOW FROM 7488  TO  7552\n",
      "WINDOW FROM 7552  TO  7616\n",
      "WINDOW FROM 7616  TO  7680\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    eeg1d,eeg2d,val,aro = get_subject_data(subject_no=1,media_no=1)\n",
    "    for i in range(0,7680,WINDOW_SIZE):\n",
    "        print(\"WINDOW FROM\",i,\" TO \",i+WINDOW_SIZE)\n",
    "        pred = np.array([val,aro]).reshape(1,2)\n",
    "        x_rnn = eeg1d[i:i+WINDOW_SIZE].reshape(-1,WINDOW_SIZE,32)\n",
    "        x_cnn = eeg2d[i:i+WINDOW_SIZE]\n",
    "        \n",
    "        sess.run(train, feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: pred})\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
