{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "* 32 participants [s01 to s32]\n",
    "* 40 pieces of music\n",
    "* 40 channels out of which the first 32 are relevant \n",
    "* 8064 readings recorded at 128Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deap_pre_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1d,eeg2d,val,aro = get_subject_data(subject_no=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 128, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44553747, -1.30729085,  0.61818628, -1.97475527, -0.76152008,\n",
       "       -0.23789995,  0.05069117, -1.54751224, -0.41305226,  1.29244011,\n",
       "        0.32111143, -0.34914847,  0.87825302,  0.87572375,  1.49782983,\n",
       "        0.60688355, -0.0739179 , -0.07013766, -0.76914595, -0.61642409,\n",
       "       -1.0477853 , -1.61118978,  0.79399241,  1.71433644, -0.83146426,\n",
       "       -0.8493887 , -0.81053115,  1.4603206 ,  1.19104473,  0.10162078,\n",
       "        1.10004079,  1.2142265 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dummy network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn_function import *\n",
    "from cnn_function import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13074696698980798675\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constant :\n",
    "WINDOW_SIZE = 128    #DO NOT CHANGE\n",
    "#For rnn layers\n",
    "INPUT_NODES = 32\n",
    "HIDDEN_ST = 32\n",
    "HOLD_PROBA = 0.5\n",
    "RNN_INPUT_SIZE = 32\n",
    "\n",
    "#For cnn layers\n",
    "CONV_IP_SHAPE = [-1,9,9,1]\n",
    "CONV1_KERNEL = [4,4,1,32]\n",
    "CONV2_KERNEL = [4,4,32,64]\n",
    "CONV3_KERNEL = [4,4,64,128]\n",
    "REDUCTION_KERNEL = [1,1,128*WINDOW_SIZE,13]\n",
    "\n",
    "#For dnn layers (for the paper code)\n",
    "N_FC_IN = 1024\n",
    "N_FC_OUT= 1024\n",
    "\n",
    "#FOR PREDICTIONS\n",
    "N_LABELS = 2\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION FORM https://github.com/ynulonger/ijcnn/blob/master/cv.py\n",
    "#FOR SHAPING THE INPUT OF LSTM\n",
    "def apply_fully_connect(x, x_size, fc_size):\n",
    "    fc_weight = init_weight([x_size, fc_size])\n",
    "    fc_bias = init_bias([fc_size])\n",
    "    return tf.nn.elu(tf.add(tf.matmul(x, fc_weight), fc_bias))\n",
    "\n",
    "#FOR READOUT OF THE FINAL LAYER\n",
    "def apply_readout(x, x_size, readout_size):\n",
    "    readout_weight = init_weight([x_size, readout_size])\n",
    "    readout_bias = init_bias([readout_size])\n",
    "    return tf.add(tf.matmul(x, readout_weight), readout_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Desktop\\bci_emotion_nn\\rnn_function.py:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "#Resetting tf default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#CNN placeholders and model variables\n",
    "x_data_cnn = tf.placeholder(dtype = tf.float32,shape=(None,9,9),name='cnn_data')\n",
    "x_image = tf.reshape(x_data_cnn,CONV_IP_SHAPE,name='cnn_image')\n",
    "\n",
    "#LAYERS\n",
    "conv1 = conv_layer(x_image,CONV1_KERNEL,name=\"convo_l1\")\n",
    "conv2 = conv_layer(conv1,CONV2_KERNEL,name=\"convo_l2\")\n",
    "conv3 = conv_layer(conv2,CONV3_KERNEL,name=\"convo_l3\")\n",
    "\n",
    "#Depth variable\n",
    "depth = tf.reshape(conv3,[-1,9,9,128* WINDOW_SIZE])\n",
    "\n",
    "#Size reduction conv layer\n",
    "reduced_data = conv_layer(depth,REDUCTION_KERNEL,name=\"conv_reduced\")\n",
    "\n",
    "#Flattening convolution layer\n",
    "shape = reduced_data.get_shape().as_list()\n",
    "final_flat = tf.reshape(reduced_data, [-1, shape[1] * shape[2] * shape[3]])\n",
    "cnn_out_fuse = final_flat\n",
    "\n",
    "#RNN placeholder and model variables\n",
    "x_data_rnn = tf.placeholder(dtype = tf.float32,shape=(None,WINDOW_SIZE,INPUT_NODES),name='rnn_data') #TIME_STEP = WINDOW_SIZE\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Shaping the RNN input\n",
    "shape = x_data_rnn.get_shape().as_list()\n",
    "rnn_in_flat = tf.reshape(x_data_rnn, [-1, shape[2]]) #[batch_size*n_time_step, n_electrode]\n",
    "rnn_fc_in = apply_fully_connect(rnn_in_flat, shape[2], N_FC_IN) #[batch_size*n_time_step, n_electrode]\n",
    "lstm_in = tf.reshape(rnn_fc_in, [-1,WINDOW_SIZE,N_FC_IN]) #[batch_size, n_time_step, n_fc_in]\n",
    "\n",
    "#Making cells\n",
    "cell1 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cell2 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cells = [cell1,cell2]\n",
    "final_cell = create_Stacked_cell(cells)\n",
    "\n",
    "#Laying out the network\n",
    "output, states = create_RNN(final_cell,lstm_in)\n",
    "\n",
    "#Unstacking the output\n",
    "output = tf.unstack(tf.transpose(output, [1, 0, 2]), name='lstm_out')\n",
    "\n",
    "#Selecting the final output form the layer\n",
    "rnn_output = output[-1] #[batch, fc_size]\n",
    "\n",
    "#Shaping the output\n",
    "lstm_fc_out = dnn_layer(rnn_output,N_FC_OUT) #[batch_size, n_fc_out]\n",
    "lstm_fc_drop = tf.nn.dropout(lstm_fc_out, keep_prob)\n",
    "\n",
    "#Placeholder for true values\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=(None,N_LABELS)) #[low, high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fuse_cnn_rnn: [None, 2077]\n"
     ]
    }
   ],
   "source": [
    "#Flattening the layer\n",
    "final_connected_layer = tf.concat([cnn_out_fuse, lstm_fc_drop], axis=1)\n",
    "shape = final_connected_layer.get_shape().as_list()\n",
    "print(\"\\nfuse_cnn_rnn:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-b4bb62a11ace>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating output variables \n",
    "y_ = apply_readout(final_connected_layer, shape[1], N_LABELS)   #(1,2)\n",
    "y_pred = tf.argmax(tf.nn.softmax(y_), 1, name=\"y_pred\")\n",
    "y_posi = tf.nn.softmax(y_, name=\"y_posi\")\n",
    "\n",
    "#Evaluation values\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y_), 1), tf.argmax(y_true, 1))\n",
    "\n",
    "#Making cost functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y_true), name='loss')\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saver and variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT:  0\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.542\n",
      "\n",
      "\n",
      "SUBJECT:  1\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  2\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  3\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  4\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  5\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  6\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  7\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  8\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  9\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  10\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.471\n",
      "\n",
      "\n",
      "SUBJECT:  11\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  12\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  13\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  14\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  15\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  16\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  17\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  18\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  19\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  20\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000741 / 1000\n",
      "Accuracy:  0.547\n",
      "\n",
      "\n",
      "SUBJECT:  21\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  22\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  23\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  24\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  25\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  26\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  27\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  28\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  29\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  30\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.482\n",
      "\n",
      "\n",
      "SUBJECT:  31\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  32\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  33\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  34\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  35\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  36\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  37\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  38\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  39\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  40\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.712\n",
      "\n",
      "\n",
      "SUBJECT:  41\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  42\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  43\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  44\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  45\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  46\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  47\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  48\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  49\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  50\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.445\n",
      "\n",
      "\n",
      "SUBJECT:  51\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  52\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  53\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  54\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  55\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  56\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  57\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  58\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  59\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  60\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.498\n",
      "\n",
      "\n",
      "SUBJECT:  61\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  62\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  63\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  64\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  65\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  66\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  67\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  68\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  69\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  70\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.527\n",
      "\n",
      "\n",
      "SUBJECT:  71\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  72\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  73\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  74\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  75\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  76\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  77\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  78\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  79\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  80\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "\n",
      "[+] Calculating accuracy\n",
      " 999 / 1000\n",
      "Accuracy:  0.511\n",
      "\n",
      "\n",
      "SUBJECT:  81\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  82\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  83\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  84\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  85\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  86\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  87\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  88\n",
      "[*] Training 60 seconds.\n",
      " 60 / 60\n",
      "SUBJECT:  89\n",
      "[*] Training 60 seconds.\n",
      " 4 / 60"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-2663aa29df1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mx_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meeg1d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(1,128,32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mx_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meeg2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_data_cnn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data_rnn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_sec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_sec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training and testing on valance\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        sub = np.random.randint(1,33)\n",
    "        print(\"SUBJECT: \",i)\n",
    "        eeg1d,eeg2d,val,aro = get_subject_data(subject_no=sub)\n",
    "        t1 = datetime.datetime.now()\n",
    "        num_sec=60                 # for total do 40*60 = 2400 seconds\n",
    "        print(\"[*] Training\",num_sec,\"seconds.\")\n",
    "        for k in range(num_sec):\n",
    "            print('\\r',k,'/',num_sec,end='')\n",
    "            pred = np.zeros((1,2))    # [low_val, high_val]\n",
    "            pred[0][val[k]]=1\n",
    "#             pred[0][aro[k]]=1\n",
    "            x_rnn = eeg1d[k].reshape(-1,WINDOW_SIZE,32)  #(1,128,32)\n",
    "            x_cnn = eeg2d[k]\n",
    "            sess.run(train, feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: pred})\n",
    "        \n",
    "        print(\"\\r\",num_sec,'/',num_sec)\n",
    "        t2 = datetime.datetime.now()\n",
    "        if(i%10 == 0):\n",
    "            test_s = np.random.randint(1,33)\n",
    "            test_eeg1d,test_eeg2d,test_val,test_aro = get_subject_data(subject_no=test_s)\n",
    "            print(\"\\n[+] Calculating accuracy\")\n",
    "            pred = []\n",
    "            tes_sec = 1000\n",
    "            for j in range(tes_sec):\n",
    "                print('\\r',j,'/',tes_sec,end='')\n",
    "                actual = np.zeros((1,2))    #[low_val, high_val]\n",
    "                actual[0][test_val[j]]=1\n",
    "                x_rnn = test_eeg1d[j].reshape(-1,WINDOW_SIZE,32)\n",
    "                x_cnn = test_eeg2d[j]\n",
    "                ret = sess.run(correct_prediction ,feed_dict = {keep_prob:1,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: actual})\n",
    "                pred.append(ret)\n",
    "            accuracy = tf.reduce_mean(tf.cast(np.array(pred), tf.float32), name='accuracy')\n",
    "            print(\"\\nAccuracy: \", sess.run(accuracy))\n",
    "            print(\"\\n\")\n",
    "    saver.save(\"TrainedModel1/model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1d5e630099db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" seconds\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmicroseconds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"microseconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "print((t2 -t1).seconds,\" seconds\",(t2 -t1).microseconds, \"microseconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
