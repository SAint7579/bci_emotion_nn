{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "* 32 participants [s01 to s32]\n",
    "* 40 pieces of music\n",
    "* 40 channels out of which the first 32 are relevant \n",
    "* 8064 readings recorded at 128Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap_pre_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1d,eeg2d,val,aro = get_subject_data(subject_no=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 128, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.65215414, -0.72894219, -0.68693938,  0.71861505, -0.13571921,\n",
       "        0.5064941 , -0.35308567,  1.61566118,  0.14702755, -1.4516925 ,\n",
       "        0.34706508,  2.16084067,  0.15708577,  0.2437785 ,  0.05400595,\n",
       "        0.37252619,  0.1410952 ,  0.74979246, -1.66170204, -0.68605256,\n",
       "        0.41627023, -1.15835518, -0.24988514, -2.35611033,  0.4761802 ,\n",
       "        1.32059778,  1.27942754, -1.75674654,  0.32296399, -0.15575763,\n",
       "       -0.4013743 ,  1.40508936])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dummy network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_function import *\n",
    "from cnn_function import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16494732306100587190\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12456908339981584812\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant :\n",
    "WINDOW_SIZE = 128    #DO NOT CHANGE\n",
    "#For rnn layers\n",
    "INPUT_NODES = 32\n",
    "HIDDEN_ST = 32\n",
    "HOLD_PROBA = 0.5\n",
    "RNN_INPUT_SIZE = 32\n",
    "\n",
    "#For cnn layers\n",
    "CONV_IP_SHAPE = [-1,9,9,1]\n",
    "CONV1_KERNEL = [4,4,1,32]\n",
    "CONV2_KERNEL = [4,4,32,64]\n",
    "CONV3_KERNEL = [4,4,64,128]\n",
    "REDUCTION_KERNEL = [1,1,128*WINDOW_SIZE,13]\n",
    "\n",
    "#For dnn layers (for the paper code)\n",
    "N_FC_IN = 1024\n",
    "N_FC_OUT= 1024\n",
    "\n",
    "#FOR PREDICTIONS\n",
    "N_LABELS = 2\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FORM https://github.com/ynulonger/ijcnn/blob/master/cv.py\n",
    "#FOR SHAPING THE INPUT OF LSTM\n",
    "def apply_fully_connect(x, x_size, fc_size):\n",
    "    fc_weight = init_weight([x_size, fc_size])\n",
    "    fc_bias = init_bias([fc_size])\n",
    "    return tf.nn.elu(tf.add(tf.matmul(x, fc_weight), fc_bias))\n",
    "\n",
    "#FOR READOUT OF THE FINAL LAYER\n",
    "def apply_readout(x, x_size, readout_size):\n",
    "    readout_weight = init_weight([x_size, readout_size])\n",
    "    readout_bias = init_bias([readout_size])\n",
    "    return tf.add(tf.matmul(x, readout_weight), readout_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:28: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:67: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Resetting tf default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#CNN placeholders and model variables\n",
    "x_data_cnn = tf.placeholder(dtype = tf.float32,shape=(None,9,9),name='cnn_data')\n",
    "x_image = tf.reshape(x_data_cnn,CONV_IP_SHAPE,name='cnn_image')\n",
    "\n",
    "#LAYERS\n",
    "conv1 = conv_layer(x_image,CONV1_KERNEL,name=\"convo_l1\")\n",
    "conv2 = conv_layer(conv1,CONV2_KERNEL,name=\"convo_l2\")\n",
    "conv3 = conv_layer(conv2,CONV3_KERNEL,name=\"convo_l3\")\n",
    "\n",
    "#Depth variable\n",
    "depth = tf.reshape(conv3,[-1,9,9,128* WINDOW_SIZE])\n",
    "\n",
    "#Size reduction conv layer\n",
    "reduced_data = conv_layer(depth,REDUCTION_KERNEL,name=\"conv_reduced\")\n",
    "\n",
    "#Flattening convolution layer\n",
    "shape = reduced_data.get_shape().as_list()\n",
    "final_flat = tf.reshape(reduced_data, [-1, shape[1] * shape[2] * shape[3]])\n",
    "cnn_out_fuse = final_flat\n",
    "\n",
    "#RNN placeholder and model variables\n",
    "x_data_rnn = tf.placeholder(dtype = tf.float32,shape=(None,WINDOW_SIZE,INPUT_NODES),name='rnn_data') #TIME_STEP = WINDOW_SIZE\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Shaping the RNN input\n",
    "shape = x_data_rnn.get_shape().as_list()\n",
    "rnn_in_flat = tf.reshape(x_data_rnn, [-1, shape[2]]) #[batch_size*n_time_step, n_electrode]\n",
    "rnn_fc_in = apply_fully_connect(rnn_in_flat, shape[2], N_FC_IN) #[batch_size*n_time_step, n_electrode]\n",
    "lstm_in = tf.reshape(rnn_fc_in, [-1,WINDOW_SIZE,N_FC_IN]) #[batch_size, n_time_step, n_fc_in]\n",
    "\n",
    "#Making cells\n",
    "cell1 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cell2 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cells = [cell1,cell2]\n",
    "final_cell = create_Stacked_cell(cells)\n",
    "\n",
    "#Laying out the network\n",
    "output, states = create_RNN(final_cell,lstm_in)\n",
    "\n",
    "#Unstacking the output\n",
    "output = tf.unstack(tf.transpose(output, [1, 0, 2]), name='lstm_out')\n",
    "\n",
    "#Selecting the final output form the layer\n",
    "rnn_output = output[-1] #[batch, fc_size]\n",
    "\n",
    "#Shaping the output\n",
    "lstm_fc_out = dnn_layer(rnn_output,N_FC_OUT) #[batch_size, n_fc_out]\n",
    "lstm_fc_drop = tf.nn.dropout(lstm_fc_out, keep_prob)\n",
    "\n",
    "#Placeholder for true values\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=(None,N_LABELS)) #[low, high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fuse_cnn_rnn: [None, 2077]\n"
     ]
    }
   ],
   "source": [
    "#Flattening the layer\n",
    "final_connected_layer = tf.concat([cnn_out_fuse, lstm_fc_drop], axis=1)\n",
    "shape = final_connected_layer.get_shape().as_list()\n",
    "print(\"\\nfuse_cnn_rnn:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-66f3a6399076>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating output variables \n",
    "y_ = apply_readout(final_connected_layer, shape[1], N_LABELS)   #(1,2)\n",
    "y_pred = tf.argmax(tf.nn.softmax(y_), 1, name=\"y_pred\")\n",
    "y_posi = tf.nn.softmax(y_, name=\"y_posi\")\n",
    "\n",
    "#Evaluation values\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y_), 1), tf.argmax(y_true, 1))\n",
    "\n",
    "#Making cost functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y_true), name='loss')\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saver and variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT:  0\n",
      "[+] Reading subject: s06\n",
      "[*] Processing: s06\n",
      " 60 %"
     ]
    }
   ],
   "source": [
    "#Training and testing on valance\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        sub = np.random.randint(1,33)\n",
    "        print(\"SUBJECT: \",sub)\n",
    "        eeg1d,eeg2d,val,aro = get_subject_data(subject_no=sub)\n",
    "        t1 = datetime.datetime.now()\n",
    "        num_sec=2400                 # for total do 40*60 = 2400 seconds\n",
    "        print(\"[*] Training\",num_sec,\"seconds.\")\n",
    "        for k in range(num_sec):\n",
    "            print('\\r',k,'/',num_sec,end='')\n",
    "            pred = np.zeros((1,2))    # [low_val, high_val]\n",
    "            pred[0][val[k]]=1         # for valence\n",
    "#             pred[0][aro[k]]=1         # for arousal\n",
    "            x_rnn = eeg1d[k].reshape(-1,WINDOW_SIZE,32)  #(1,128,32)\n",
    "            x_cnn = eeg2d[k]\n",
    "            sess.run(train, feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: pred})\n",
    "        \n",
    "        print(\"\\r\",num_sec,'/',num_sec)\n",
    "        t2 = datetime.datetime.now()\n",
    "        if not i%20:\n",
    "            test_s = np.random.randint(1,33)\n",
    "            test_eeg1d,test_eeg2d,test_val,test_aro = get_subject_data(subject_no=test_s)\n",
    "            print(\"\\n[+] Calculating accuracy\")\n",
    "            pred = []\n",
    "            tes_sec = 1000\n",
    "            for j in range(tes_sec):\n",
    "                print('\\r',j,'/',tes_sec,end='')\n",
    "                actual = np.zeros((1,2))    #[low_val, high_val]\n",
    "                actual[0][test_val[j]]=1\n",
    "                x_rnn = test_eeg1d[j].reshape(-1,WINDOW_SIZE,32)\n",
    "                x_cnn = test_eeg2d[j]\n",
    "                ret = sess.run(correct_prediction ,feed_dict = {keep_prob:1,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: actual})\n",
    "                pred.append(ret)\n",
    "            accuracy = tf.reduce_mean(tf.cast(np.array(pred), tf.float32), name='accuracy')\n",
    "            print(\"\\nAccuracy: \", sess.run(accuracy))\n",
    "            print(\"\\n\")\n",
    "    saver.save(\"TrainedModel1/model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1d5e630099db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" seconds\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmicroseconds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"microseconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "print((t2 -t1).seconds,\" seconds\",(t2 -t1).microseconds, \"microseconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
