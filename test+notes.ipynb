{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "* 32 participants [s01 to s32]\n",
    "* 40 pieces of music\n",
    "* 40 channels out of which the first 32 are relevant \n",
    "* 8064 readings recorded at 128Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deap_pre_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Reading subject: s31 Media: [19, 11, 12, 13, 20]\n"
     ]
    }
   ],
   "source": [
    "eeg1d,eeg2d,val,aro = get_subject_data(subject_no=31,media_no=[19,11,12,13,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38400"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eeg2d.reshape(-1,9,9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7680, 9, 9)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dummy network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn_function import *\n",
    "from cnn_function import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2767076687531676217\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1477437030\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11869577556536837693\n",
      "physical_device_desc: \"device: 0, name: GeForce 930MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constant :\n",
    "WINDOW_SIZE = 128\n",
    "#For rnn layers\n",
    "INPUT_NODES = 32\n",
    "HIDDEN_ST = 32\n",
    "HOLD_PROBA = 0.5\n",
    "RNN_INPUT_SIZE = 32\n",
    "\n",
    "#For cnn layers\n",
    "CONV_IP_SHAPE = [-1,9,9,1]\n",
    "CONV1_KERNEL = [4,4,1,32]\n",
    "CONV2_KERNEL = [4,4,32,64]\n",
    "CONV3_KERNEL = [4,4,64,128]\n",
    "REDUCTION_KERNEL = [1,1,128*WINDOW_SIZE,13]\n",
    "\n",
    "#For dnn layers (for the paper code)\n",
    "N_FC_IN = 1024\n",
    "N_FC_OUT= 1024\n",
    "\n",
    "#FOR PREDICTIONS\n",
    "N_LABELS = 2\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION FORM https://github.com/ynulonger/ijcnn/blob/master/cv.py\n",
    "#FOR SHAPING THE INPUT OF LSTM\n",
    "def apply_fully_connect(x, x_size, fc_size):\n",
    "    fc_weight = init_weight([x_size, fc_size])\n",
    "    fc_bias = init_bias([fc_size])\n",
    "    return tf.nn.elu(tf.add(tf.matmul(x, fc_weight), fc_bias))\n",
    "\n",
    "#FOR READOUT OF THE FINAL LAYER\n",
    "def apply_readout(x, x_size, readout_size):\n",
    "    readout_weight = init_weight([x_size, readout_size])\n",
    "    readout_bias = init_bias([readout_size])\n",
    "    return tf.add(tf.matmul(x, readout_weight), readout_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Desktop\\bci_emotion_nn\\rnn_function.py:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    }
   ],
   "source": [
    "#Resetting tf default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#CNN placeholders and model variables\n",
    "x_data_cnn = tf.placeholder(dtype = tf.float32,shape=(None,9,9),name='cnn_data')\n",
    "x_image = tf.reshape(x_data_cnn,CONV_IP_SHAPE,name='cnn_image')\n",
    "\n",
    "#LAYERS\n",
    "conv1 = conv_layer(x_image,CONV1_KERNEL,name=\"convo_l1\")\n",
    "conv2 = conv_layer(conv1,CONV2_KERNEL,name=\"convo_l2\")\n",
    "conv3 = conv_layer(conv2,CONV3_KERNEL,name=\"convo_l3\")\n",
    "\n",
    "#Depth variable\n",
    "depth = tf.reshape(conv3,[-1,9,9,128* WINDOW_SIZE])\n",
    "\n",
    "#Size reduction conv layer\n",
    "reduced_data = conv_layer(depth,REDUCTION_KERNEL,name=\"conv_reduced\")\n",
    "\n",
    "#Flattening convolution layer\n",
    "shape = reduced_data.get_shape().as_list()\n",
    "final_flat = tf.reshape(reduced_data, [-1, shape[1] * shape[2] * shape[3]])\n",
    "cnn_out_fuse = final_flat\n",
    "\n",
    "#RNN placeholder and model variables\n",
    "x_data_rnn = tf.placeholder(dtype = tf.float32,shape=(None,WINDOW_SIZE,INPUT_NODES),name='rnn_data') #TIME_STEP = WINDOW_SIZE\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Shaping the RNN input\n",
    "shape = x_data_rnn.get_shape().as_list()\n",
    "rnn_in_flat = tf.reshape(x_data_rnn, [-1, shape[2]]) #[batch_size*n_time_step, n_electrode]\n",
    "rnn_fc_in = apply_fully_connect(rnn_in_flat, shape[2], N_FC_IN) #[batch_size*n_time_step, n_electrode]\n",
    "lstm_in = tf.reshape(rnn_fc_in, [-1,WINDOW_SIZE,N_FC_IN]) #[batch_size, n_time_step, n_fc_in]\n",
    "\n",
    "#Making cells\n",
    "cell1 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cell2 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cells = [cell1,cell2]\n",
    "final_cell = create_Stacked_cell(cells)\n",
    "\n",
    "#Laying out the network\n",
    "output, states = create_RNN(final_cell,lstm_in)\n",
    "\n",
    "#Unstacking the output\n",
    "output = tf.unstack(tf.transpose(output, [1, 0, 2]), name='lstm_out')\n",
    "\n",
    "#Selecting the final output form the layer\n",
    "rnn_output = output[-1] #[batch, fc_size]\n",
    "\n",
    "#Shaping the output\n",
    "lstm_fc_out = dnn_layer(rnn_output,N_FC_OUT) #[batch_size, n_fc_out]\n",
    "lstm_fc_drop = tf.nn.dropout(lstm_fc_out, keep_prob)\n",
    "\n",
    "#Placeholder for true values\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=(None,N_LABELS)) #[Valance, Arousal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fuse_cnn_rnn: [None, 2077]\n"
     ]
    }
   ],
   "source": [
    "#Flattening the layer\n",
    "final_connected_layer = tf.concat([cnn_out_fuse, lstm_fc_drop], axis=1)\n",
    "shape = final_connected_layer.get_shape().as_list()\n",
    "print(\"\\nfuse_cnn_rnn:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-9788048c18b1>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating output variables \n",
    "y_ = apply_readout(final_connected_layer, shape[1], N_LABELS)\n",
    "y_pred = tf.argmax(tf.nn.softmax(y_), 1, name=\"y_pred\")\n",
    "y_posi = tf.nn.softmax(y_, name=\"y_posi\")\n",
    "\n",
    "#Making cost functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y_true), name='loss')\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_6:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saver and variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMAINING:\n",
    "* Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7680, 9, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7680, 32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT:  0\n",
      "[+] Reading subject: s04 Media: 0\n",
      "Calculating accuracy\n",
      "[+] Reading subject: s02 Media: [ 5 16 20  5 25 38 24 13 36 18]\n",
      "test_val [0 0]\n",
      "[[0 1]]\n",
      "ON STEP:  0 \t Accuracy=  [[ 355.71487427  372.92541504]]\n",
      "[[0 0]]\n",
      "ON STEP:  0 \t Accuracy=  [[ 357.08575439  389.95996094]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-fd47c50d3cdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_val\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_aro\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0mx_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_eeg1d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mx_cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_eeg2d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(2):\n",
    "        sub = np.random.randint(0,33)\n",
    "        print(\"SUBJECT: \",i)\n",
    "        for j in range(0,40):\n",
    "            eeg1d,eeg2d,val,aro = get_subject_data(subject_no=sub,media_no=j)\n",
    "            t1 = datetime.datetime.now()\n",
    "            for k in range(0,7680,WINDOW_SIZE):\n",
    "                pred = np.array([val,aro]).reshape(1,2)\n",
    "                x_rnn = eeg1d[k:k+WINDOW_SIZE].reshape(-1,WINDOW_SIZE,32)\n",
    "                x_cnn = eeg2d[k:k+WINDOW_SIZE]\n",
    "                sess.run(train, feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: pred})\n",
    "            \n",
    "            if j %1 == 0:\n",
    "                print(\"Calculating accuracy\")\n",
    "                test_s = np.random.randint(0,33)\n",
    "                test_m = np.random.randint(0,40,size=[10])\n",
    "                test_eeg1d,test_eeg2d,test_val,test_aro = get_subject_data(subject_no=test_s,media_no=test_m)\n",
    "                print(\"test_val\", test_val)\n",
    "                for med in range(10):\n",
    "                    actual = np.array([test_val[med],test_aro[med]]).reshape(1,2)\n",
    "                    x_rnn = test_eeg1d[med][0:WINDOW_SIZE].reshape(-1,WINDOW_SIZE,32)\n",
    "                    x_cnn = test_eeg2d[med][0:WINDOW_SIZE]\n",
    "                    correct = tf.equal(y_pred,tf.argmax(y_true,axis=1))\n",
    "                    acc  = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "                    print(actual)\n",
    "                    print(\"ON STEP: \",j,\"\\t Accuracy= \",sess.run(y_,feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: actual}))\n",
    "            \n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-1d5e630099db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" seconds\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmicroseconds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"microseconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "print((t2 -t1).seconds,\" seconds\",(t2 -t1).microseconds, \"microseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
