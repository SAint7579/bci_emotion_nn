{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "* 32 participants [s01 to s32]\n",
    "* 40 pieces of music\n",
    "* 40 channels out of which the first 32 are relevant \n",
    "* 8064 readings recorded at 128Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap_pre_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1d,eeg2d,labels = get_subject_data(2,\"aro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 128, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1d,eeg2d,labels = get_subject_data(5,\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dummy network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_function import *\n",
    "from cnn_function import *\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15171058008212375722\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11571530746305894046\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant :\n",
    "WINDOW_SIZE = 128    #DO NOT CHANGE\n",
    "#For rnn layers\n",
    "INPUT_NODES = 32\n",
    "HIDDEN_ST = 32\n",
    "HOLD_PROBA = 0.5\n",
    "RNN_INPUT_SIZE = 32\n",
    "\n",
    "#For cnn layers\n",
    "CONV_IP_SHAPE = [-1,9,9,1]\n",
    "CONV1_KERNEL = [4,4,1,32]\n",
    "CONV2_KERNEL = [4,4,32,64]\n",
    "CONV3_KERNEL = [4,4,64,128]\n",
    "REDUCTION_KERNEL = [1,1,128*WINDOW_SIZE,13]\n",
    "\n",
    "#For dnn layers (for the paper code)\n",
    "N_FC_IN = 1024\n",
    "N_FC_OUT= 1024\n",
    "\n",
    "#FOR PREDICTIONS\n",
    "N_LABELS = 2\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FORM https://github.com/ynulonger/ijcnn/blob/master/cv.py\n",
    "#FOR SHAPING THE INPUT OF LSTM\n",
    "def apply_fully_connect(x, x_size, fc_size):\n",
    "    fc_weight = init_weight([x_size, fc_size])\n",
    "    fc_bias = init_bias([fc_size])\n",
    "    return tf.nn.elu(tf.add(tf.matmul(x, fc_weight), fc_bias))\n",
    "\n",
    "#FOR READOUT OF THE FINAL LAYER\n",
    "def apply_readout(x, x_size, readout_size):\n",
    "    readout_weight = init_weight([x_size, readout_size])\n",
    "    readout_bias = init_bias([readout_size])\n",
    "    return tf.add(tf.matmul(x, readout_weight), readout_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:15: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:28: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/archer/machine_learning/bci_emotion_nn/rnn_function.py:67: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Resetting tf default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#CNN placeholders and model variables\n",
    "x_data_cnn = tf.placeholder(dtype = tf.float32,shape=(None,9,9),name='cnn_data')\n",
    "x_image = tf.reshape(x_data_cnn,CONV_IP_SHAPE,name='cnn_image')\n",
    "\n",
    "#LAYERS\n",
    "conv1 = conv_layer(x_image,CONV1_KERNEL,name=\"convo_l1\")\n",
    "conv2 = conv_layer(conv1,CONV2_KERNEL,name=\"convo_l2\")\n",
    "conv3 = conv_layer(conv2,CONV3_KERNEL,name=\"convo_l3\")\n",
    "\n",
    "#Depth variable\n",
    "depth = tf.reshape(conv3,[-1,9,9,128* WINDOW_SIZE])\n",
    "\n",
    "#Size reduction conv layer\n",
    "reduced_data = conv_layer(depth,REDUCTION_KERNEL,name=\"conv_reduced\")\n",
    "\n",
    "#Flattening convolution layer\n",
    "shape = reduced_data.get_shape().as_list()\n",
    "final_flat = tf.reshape(reduced_data, [-1, shape[1] * shape[2] * shape[3]])\n",
    "cnn_out_fuse = final_flat\n",
    "\n",
    "#RNN placeholder and model variables\n",
    "x_data_rnn = tf.placeholder(dtype = tf.float32,shape=(None,WINDOW_SIZE,INPUT_NODES),name='rnn_data') #TIME_STEP = WINDOW_SIZE\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Shaping the RNN input\n",
    "shape = x_data_rnn.get_shape().as_list()\n",
    "rnn_in_flat = tf.reshape(x_data_rnn, [-1, shape[2]]) #[batch_size*n_time_step, n_electrode]\n",
    "rnn_fc_in = apply_fully_connect(rnn_in_flat, shape[2], N_FC_IN) #[batch_size*n_time_step, n_electrode]\n",
    "lstm_in = tf.reshape(rnn_fc_in, [-1,WINDOW_SIZE,N_FC_IN]) #[batch_size, n_time_step, n_fc_in]\n",
    "\n",
    "#Making cells\n",
    "cell1 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cell2 = dropout_wrapper(keep_prob, create_LSTM_cell(HIDDEN_ST))\n",
    "cells = [cell1,cell2]\n",
    "final_cell = create_Stacked_cell(cells)\n",
    "\n",
    "#Laying out the network\n",
    "output, states = create_RNN(final_cell,lstm_in)\n",
    "\n",
    "#Unstacking the output\n",
    "output = tf.unstack(tf.transpose(output, [1, 0, 2]), name='lstm_out')\n",
    "\n",
    "#Selecting the final output form the layer\n",
    "rnn_output = output[-1] #[batch, fc_size]\n",
    "\n",
    "#Shaping the output\n",
    "lstm_fc_out = dnn_layer(rnn_output,N_FC_OUT) #[batch_size, n_fc_out]\n",
    "lstm_fc_drop = tf.nn.dropout(lstm_fc_out, keep_prob)\n",
    "\n",
    "#Placeholder for true values\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=(None,N_LABELS)) #[low, high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fuse_cnn_rnn: [None, 2077]\n"
     ]
    }
   ],
   "source": [
    "#Flattening the layer\n",
    "final_connected_layer = tf.concat([cnn_out_fuse, lstm_fc_drop], axis=1)\n",
    "shape = final_connected_layer.get_shape().as_list()\n",
    "print(\"\\nfuse_cnn_rnn:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-66f3a6399076>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating output variables \n",
    "y_ = apply_readout(final_connected_layer, shape[1], N_LABELS)   #(1,2)\n",
    "y_pred = tf.argmax(tf.nn.softmax(y_), 1, name=\"y_pred\")\n",
    "y_posi = tf.nn.softmax(y_, name=\"y_posi\")\n",
    "\n",
    "#Evaluation values\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y_), 1), tf.argmax(y_true, 1))\n",
    "\n",
    "#Making cost functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y_true), name='loss')\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saver and variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aro_or_val=\"aro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from aro_TrainedModel1/model\n",
      "[*] Model Restored.\n",
      "1.) SUBJECT: 13\n",
      "[*] Training 2400 seconds.\n",
      " 14 / 2400"
     ]
    }
   ],
   "source": [
    "#Training and testing on valance\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    try:\n",
    "        saver.restore(sess, aro_or_val+\"_TrainedModel1/model\")\n",
    "        print(\"[*] Model Restored.\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for i in range(10):        # num of people\n",
    "            sub = np.random.randint(1,33)\n",
    "            print(i+1,\"\\b.) SUBJECT:\",sub)\n",
    "            eeg1d,eeg2d,labels = get_subject_data(sub,aro_or_val)\n",
    "            t1 = datetime.datetime.now()\n",
    "            num_sec=2400                 # for total do 40*60 = 2400 seconds\n",
    "            print(\"[*] Training\",num_sec,\"seconds.\")\n",
    "            for k in range(num_sec):\n",
    "                print('\\r',k,'/',num_sec,end='')\n",
    "                pred_labels=labels[k].reshape(1,2)\n",
    "                x_rnn = eeg1d[k].reshape(-1,WINDOW_SIZE,32)  #(1,128,32)\n",
    "                x_cnn = eeg2d[k]\n",
    "                sess.run(train, feed_dict = {keep_prob:0.5,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: pred_labels})\n",
    "\n",
    "            print(\"\\r\",num_sec,'/',num_sec)\n",
    "            t2 = datetime.datetime.now()\n",
    "            print((t2 -t1).seconds,\" seconds\",(t2 -t1).microseconds, \"microseconds\")\n",
    "            if not i%5:\n",
    "                test_s = np.random.randint(1,33)\n",
    "                test_eeg1d,test_eeg2d,test_labels = get_subject_data(test_s,aro_or_val)\n",
    "                print(\"\\n[+] Calculating accuracy\")\n",
    "                pred = []\n",
    "                tes_sec = 1000\n",
    "                for j in range(tes_sec):\n",
    "                    print('\\r',j,'/',tes_sec,end='')\n",
    "                    actual = test_labels[j].reshape(1,2)\n",
    "                    x_rnn = test_eeg1d[j].reshape(-1,WINDOW_SIZE,32)\n",
    "                    x_cnn = test_eeg2d[j]\n",
    "                    ret = sess.run(correct_prediction ,feed_dict = {keep_prob:1,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: actual})\n",
    "                    pred.append(ret)\n",
    "                accuracy = tf.reduce_mean(tf.cast(np.array(pred), tf.float32), name='accuracy')\n",
    "                print(\"\\nAccuracy: \", sess.run(accuracy))\n",
    "                print(\"\\n\")\n",
    "        saver.save(sess, aro_or_val+\"_TrainedModel1/model\")\n",
    "        print(\"[*] Model Saved.\")\n",
    "    except KeyboardInterrupt:\n",
    "        saver.save(sess, aro_or_val+\"_TrainedModel1/model\")\n",
    "        print(\"\\n[*] Model Saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        saver.restore(sess, aro_or_val+\"_TrainedModel1/model\")\n",
    "        test_s = np.random.randint(1,33)\n",
    "        test_eeg1d,test_eeg2d,test_labels = get_subject_data(test_s,aro_or_val)\n",
    "        print(\"\\n[+] Calculating accuracy\")\n",
    "        pred = []\n",
    "        tes_sec = 1000\n",
    "        for j in range(tes_sec):\n",
    "            print('\\r',j,'/',tes_sec,end='')\n",
    "            actual = test_labels[j].reshape(1,2)\n",
    "            x_rnn = test_eeg1d[j].reshape(-1,WINDOW_SIZE,32)\n",
    "            x_cnn = test_eeg2d[j]\n",
    "            ret = sess.run(correct_prediction ,feed_dict = {keep_prob:1,x_data_cnn:x_cnn, x_data_rnn: x_rnn, y_true: actual})\n",
    "            pred.append(ret)\n",
    "        accuracy = tf.reduce_mean(tf.cast(np.array(pred), tf.float32), name='accuracy')\n",
    "        print(\"\\nAccuracy: \", sess.run(accuracy))\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
